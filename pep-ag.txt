PEP: XXX
Title: Asynchronous Generators
Version: $Revision$
Last-Modified: $Date$
Author: Yury Selivanov <yury@magic.io>
Discussions-To: <python-dev@python.org>
Status: Draft
Type: Standards Track
Content-Type: text/x-rst
Created: 28-Jul-2016
Python-Version: 3.5
Post-History:


Abstract
========


Rationale and Goals
===================

1. ``async for`` is incomplete without async gens

2. It's super hard to implement a complex async iterators using
__anext__; async generators streamline that

3. Speed -- async gens are 2x faster than implementing iters with
__anext__.

4. New python power: streaming of messages from websoket or
channels, pipelines for processing async data, @asynccontextmanager
and alike.


Specification
=============

This proposal introduces a concept of asynchronous generators to
Python.

This specification presumes knowledge of the implementation of
generators and coroutines in Python (PEP 342, PEP 380 and PEP 492).


Asynchronous Generators
-----------------------

*Generators* in Python are defined by adding a ``yield`` keyword
to functions::

    def func():            # a function
        return

    def genfunc():         # a generator function
        yield

We propose to use the same approach to define
*asynchronous generators*::

    async def coro():      # a coroutine function
        await smth()

    async def asyncgen():  # an asynchronous generator function
        await smth()
        yield val

The result of calling an *asynchronous generator function* is
an *asynchronous generator object*, which implements the asynchronous
iteration protocol defined in PEP 492.

It is a ``SyntaxError`` to have a non-empty ``return`` statement in
asynchronous generators.


Asynchronous Iteration Protocol
-------------------------------

The protocol requires two magic methods to be implemented:

1. An ``__aiter__`` method returning an *asynchronous iterator*.
2. An ``__anext__`` method returning an *awaitable* object, which uses
   ``StopIteration`` exception to "yield" values, and
   ``StopAsyncIteration`` exception to signal the end of the iteration.

Asynchronous generators define both of these methods::

    async def genfunc():
        yield 1
        yield 2

    gen = genfunc()

    assert gen.__aiter__() is gen

    assert await gen.__anext__() == 1
    assert await gen.__anext__() == 2

    with assertRaises(StopAsyncIteration):
        await gen.__anext__()


async for
---------

Asynchronous generators can be used with the ``async for`` statement::

    async def ticker(delay, to):
        """Print numbers from 0 to `to` every `delay` seconds."""
        i = 0
        while i < to:
            yield i
            i += 1
            await asyncio.sleep(delay)

    async for val in ticker(1, 100):
        print(f'tick: {val}')

An equivalent implementation of the ``ticker`` generator using
asynchronous iteration protocol::

    class ticker:
        """Print numbers from 0 to `to` every `delay` seconds."""

        def __init__(self, delay, to):
            self.delay = delay
            self.i = 0
            self.to = to

        def __aiter__(self):
            return self

        async def __anext__(self):
            i = self.i
            if i >= self.to:
                raise StopAsyncIteration
            self.i += 1
            if i:
                await asyncio.sleep(self.delay)
            return i

Even for the simplest use cases, implementing iteration logic using
asynchronous iteration protocol quickly leads to a hard to read and
error-prone code.


Finalization
------------

PEP 492 requires an event loop or a scheduler to run coroutines.
Because asynchronous generators are meant to be used from coroutines,
they also require an event loop to run and finalize them.

Asynchronous generators can have ``try..finally`` blocks, as well as
``async with``.  It's important to provide a way to guarantee that
even when partially iterated, and then garbage collected, generators can
be safely finalized.  For example::

    async def square_series(con, to):
        async with con.transaction():
            cursor = con.cursor(
                'SELECT generate_series(0, $1) AS i', to)
            async for row in cursor:
                yield row['i'] ** 2

    async for i in square_series(con, 100):
        if i == 100:
            break

The above code defines an asynchronous generator that uses
``async with`` to iterate over a database cursor in a transaction.
The generator is then iterated over with ``async for``, which interrupts
the iteration at some moment.

The ``square_series()`` generator will be then garbage collected,
and without a mechanism to asynchronously close the generator, Python
interpreter would not be able to do anything.

To solve this problem we propose to add the following:

1. Implement an ``aclose`` method on asynchronous generators.
   ``aclose`` must return an *awaitable* object, which when awaited
   will throw a ``GeneratorExit`` into the suspended generator, and
   iterate over it until it raises ``GeneratorExit`` or
   ``StopAsyncIteration``.  This is very similar to what method
   ``close()`` does to regular Python generators, except that we need
   an event loop to execute ``aclose()``.

2. If the asynchronous generator executes a ``yield`` expression in
   its ``finally`` block (using ``await`` is fine, though), a
   ``RuntimeError`` is raised, and the finalization is aborted::

        async def gen():
            try:
                yield
            finally:
                yield                    # Can't use 'yield'
                await asyncio.sleep(1)   # Can use 'await'

3. Two new methods will be added to the ``sys`` module:
   ``set_asyncgen_finalizer`` and ``get_asyncgen_finalizer``.
   The former allows to set a callback, which the interpreter will
   call when the asynchronous generator is about to be garbage
   collected.  The finalizer can then schedule generator's ``aclose()``
   awaitable to the currently running event loop.

   For instance, here's how asyncio can be modified to allow
   safe asynchronous generators finalization::

       # asyncio/base_events.py

       class BaseEventLoop:

           def run_forever(self):
               ...
               old_finalizer = sys.get_asyncgen_finalizer()
               sys.set_asyncgen_finalizer(self._finalize_asyncgen)
               try:
                   ...
               finally:
                   sys.set_asyncgen_finalizer(old_finalizer)
                   ...

           def _finalize_asyncgen(self, gen):
               self.create_task(gen.aclose())

   Both functions are thread-specific, meaning that several event
   loops running in parallel threads can use them safely.

The idea behind ``sys.set_asyncgen_finalizer`` is to allow event loops
to handle generators finalization, so that the end-users don't need
to care about this problem.


Asynchronous Generator Object
-----------------------------

The object is modeled after the standard Python generator object.
Essentially, the behaviour of asynchronous generators is designed
to replicate the behaviour of synchronous generators, with the only
difference in that the API is asynchronous.

The following methods and properties are defined:

1. ``agen.__aiter__()``: Returns ``agen``.

2. ``agen.__anext__()``: Returns an *awaitable*, that performs one
   asynchronous generator iteration when awaited.

3. ``agen.anext(val)``: Returns an *awaitable*, that pushes the
   ``val`` object in the ``agen`` generator.  When the ``agen`` has
   not yet been iterated, ``val`` must be ``None``.

   Example::

       async def gen():
           await asyncio.sleep(0.1)
           v = yield 42
           print(v)
           await asyncio.sleep(0.1)

       g = gen()
       await g.send(None)      # Will return 42
       await g.send('hello')   # Will print 'hello' and
                               # raise StopAsyncIteration
                               # (after sleeping for 0.1 seconds)

4. ``agen.athrow(typ, [val, [tb]])``: Returns an *awaitable*, that
   throws an exception tuple into the ``agen`` generator.

   Example::

       async def gen():
           try:
               await asyncio.sleep(0.1)
               yield 'hello'
           except ZeroDivisionError:
               await asyncio.sleep(0.2)
               yield 'world'

       g = gen()
       v = await g.asend(None)
       print(v)                # Will print 'hello' after sleeping 0.1s
       v = await g.athrow(ZeroDivisionError)
       print(v)                # Will print 'world' after sleeping 0.2s

5. ``agen.aclose()``: Returns an *awaitable*, that throws a
   ``GeneratorExit`` exception into the generator.  The *awaitable* can
   either return a yielded value, if ``agen`` handled the exception,
   or ``agen`` will be closed and the exception will propagate back
   to the caller.

6. ``agen.__name__`` and ``agen.__qualname__``: readable and writable
   name and qualname attributes.

7. ``agen.ag_await``: The object that ``agen`` is currently awaiting on,
   or ``None``.

8. ``agen.ag_frame``, ``agen.ag_running``, and ``agen.ag_code``:
   defined in the same way as similar attributes of standard generators.


New Standard Library Functions and Types
----------------------------------------

1. ``types.AsyncGeneratorType`` -- type of asynchronous generator
   object.

2. ``sys.set_asyncgen_finalizer()`` and ``sys.get_asyncgen_finalizer()``
   methods to set up asynchronous generators finalizers in event loops.

3. ``inspect.isasyncgen()`` and ``inspect.isasyncgenfunction()``
   introspection functions.


Backwards Compatibility
-----------------------

The proposal is fully backwards compatible.

In Python 3.5 it is a ``SyntaxError`` to define an ``async def``
function with a ``yield`` expression inside, therefore it's safe to
introduce asynchronous generators in 3.6.


Performance
===========

Regular Generators
------------------

There is no performance degradation for regular generators.
The following micro benchmark runs for the same time on CPython with
and without asynchronous generators::

    def gen():
        i = 0
        while i < 100000000:
            yield i
            i += 1

    list(gen())


Improvements over asynchronous iterators
----------------------------------------

The following micro-benchmark shows that asynchronous generators
are about **2x faster** than asynchronous iterators implemented in
pure Python:

    async def agen():
        i = 0
        while i < N:
            yield i
            i += 1


    class AIter:
        def __init__(self):
            self.i = 0

        def __aiter__(self):
            return self

        async def __anext__(self):
            i = self.i
            if i >= N:
                raise StopAsyncIteration
            self.i += 1
            return i


Design Considerations
=====================


``aiter()`` and ``anext()`` builtins
------------------------------------

Originally PEP 492 defined ``__aiter__`` as a method that should
return an *awaitable* object, resulting in an asynchronous iterator.

However, in CPython 3.5.2, ``__aiter__`` was redefined to return
asynchronous iterators directly.  To avoid breaking backwards
compatibility, it was decided that Python 3.6 will support both
ways: ``__aiter__`` can still return an *awaitable* with
``DeprecationWarning`` being issued.

Because of this dual nature of ``__aiter__`` in Python 3.6, we can't
add a synchronous implementation of ``aiter()`` built-in.  Therefore,
it is proposed to wait until Python 3.7.


Asynchronous list/dict/set comprehensions
-----------------------------------------

Syntax for asynchronous comprehensions is unrelated to the asynchronous
generators machinery, and should be considered in a separate PEP.


Asynchronous ``yield from``
---------------------------

While it is theoretically possible to implement ``yield from`` support
for asynchronous generators, it would require to seriously
re-architecture current generators implementation.

``yield from`` is also less critical for asynchronous generators, since
there is no need provide a mechanism of implementing another coroutines
protocol on top of coroutines.  To compose asynchronous generators a
simple ``async for`` loop can be used::

    async def g1():
        yield 1
        yield 2

    async def g2():
        async for v in g1():
            yield v


Why do we need ``asend`` and ``athrow`` methods
-----------------------------------------------

They allow to implement concepts similar to
``contextlib.contextmanager`` but for asynchronous generators.
For instance, with the current design, it is possible to implement
the following pattern::

    @async_context_manager
    async def ctx():
        await open()
        try:
            yield
        finally:
            await close()

    async with ctx():
        await ...

Another reason is that even if we don't expose ``asend`` and ``athrow``
methods, it would still be possible to push data and throw exceptions
into asynchronous generators using the ``__anext__`` object.  Since
``__anext__`` method returns a coroutine-like *awaitable*, that defines
``send`` and ``throw`` methods, it is possible to use them directly.


Implementation
==============

The complete reference implementation is available at [1]_.


References
==========

.. [1] https://github.com/1st1/cpython/tree/async_gen


Copyright
=========

This document has been placed in the public domain.

..
   Local Variables:
   mode: indented-text
   indent-tabs-mode: nil
   sentence-end-double-space: t
   fill-column: 70
   coding: utf-8
   End:
